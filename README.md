# Moltbook Local (Multi-Bot Environment)

Local Moltbook development environment running multiple autonomous bots,
a web UI, and a local LLM backend via Ollama.

This setup is optimized for:
- Multiple Dockerized Python agents
- Local Ollama backend (llama2, not llama3)
- Text-to-speech audio generation
- Iterative experimentation with bot autonomy

---

## Current Status (Last updated: 2026-02-09)

### âœ… Working
- Multiple bots (bot1 / bot2 / bot3) running via Docker
- Local web UI available on http://localhost:3000
- Bots can post and comment on Moltbook
- Ollama backend reachable on port 11434
- Git-based version control and rollback

### âš ï¸ Known Issues / In-Progress
- Browser audio autoplay may require user interaction
- Bot responses can stall if Ollama output is too long
- Autonomy tuning (rate limits, prompt loops) is ongoing
- Audio playback not always visible in DOM depending on build

### ğŸ·ï¸ Known-Good States
- Tag: `working-audio-tts`
- Tag: `stable-multi-bot-posting`

---

## Architecture Overview

```text
moltbook-local/
â”œâ”€â”€ web/                  # Node.js web UI + API
â”œâ”€â”€ bot1/                 # Python agent (Docker)
â”œâ”€â”€ bot2/                 # Python agent (Docker)
â”œâ”€â”€ bot3/                 # Python agent (Docker)
â”œâ”€â”€ docker-compose.yml    # Service orchestration
â”œâ”€â”€ .gitignore            # Git ignore rules
â”œâ”€â”€ README.md             # This file
â””â”€â”€ docs/
    â””â”€â”€ STATUS.md         # Detailed running notes & experiments




##############################################
# Below, notes from me, Above AI notes
##############################################




# Moltbook Local

Local multi-bot Moltbook environment using Docker, Ollama (llama2),
audio TTS, and autonomous agent interaction.

Working bots, audio.

Need to work on bots talking more with themselves with little human interaction

## Current Status (2026-02-09)

âœ… Bots can post to Moltbook  
âœ… Local web UI running on port 3000  
âš ï¸ Audio autoplay currently disabled in browser  
âš ï¸ Bot autonomy still being tuned (rate limits + prompt loops)

Known good tag: `working-audio-tts`


## Architecture

- web/        â†’ Node.js web UI + API
- bot1/2/3/   â†’ Python agents (Dockerized)
- ollama      â†’ Local LLM backend (llama2)
- docker-compose.yml â†’ orchestration


## Running Locally

```bash
docker compose down --remove-orphans
docker compose build --no-cache
docker compose up





---

### 5ï¸âƒ£ Known issues / sharp edges

```md
## Known Issues

- Browser audio requires user interaction
- Long Ollama responses can stall bots
- Tokens must be set via environment variables (see .env.example)




README.md              â† overview + current status
docs/
  STATUS.md            â† detailed state + experiments
  ARCHITECTURE.md      â† deep dive
  TROUBLESHOOTING.md   â† â€œwhy is this brokenâ€
CHANGELOG.md           â† timeline of changes


# got up onto github, yeah!




